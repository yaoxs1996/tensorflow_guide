{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600151572264",
   "display_name": "Python 3.7.9 64-bit ('no-gpu': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 深度卷积生成对抗网络"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'2.2.0'"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "source": [
    "## 加载准备数据集"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype(\"float32\")\n",
    "train_images = (train_images - 127.5) / 127.5       # 将图片标准化到[-1, 1]区间内"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 批量化和打乱数据\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "source": [
    "## 创建模型"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 生成器\n",
    "从上采样层来种子（随机噪声）中产生图片"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_genrator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7,7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256)\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding=\"same\", use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding=\"same\", use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding=\"same\", use_bias=False,activation=\"tanh\"))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7fc0083bdc50>"
     },
     "metadata": {},
     "execution_count": 9
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "# 使用未经训练的生成器创建一张图片\n",
    "generator = make_genrator_model()\n",
    "\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap=\"gray\")"
   ]
  },
  {
   "source": [
    "### 判别器\n",
    "基于CNN的图片分类器"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding=\"same\", input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding=\"same\"))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tf.Tensor([[-0.00119956]], shape=(1, 1), dtype=float32)\n"
    }
   ],
   "source": [
    "# 使用未经训练的判别器来对图片的真伪进行判断。真实图片输出正值，伪造图片输出负值\n",
    "discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_image)\n",
    "print(decision)"
   ]
  },
  {
   "source": [
    "## 定义损失函数和优化器"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "source": [
    "### 判别器损失\n",
    "量化判别器判断真伪图片的能力"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "source": [
    "### 生成器损失\n",
    "生成器损失量化其欺骗判别器的能力"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 优化器\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"./training_checkpoints\"\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "    discriminator_optimizer=discriminator_optimizer,\n",
    "    generator=generator,\n",
    "    discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 定义训练循环\n",
    "EPOCHS = 50\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "source": [
    "### 生成与保存图片"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    predictions = model(test_input, training=False)\n",
    "\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.savefig(\"image_at_epoch_{:04d}.png\".format(epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        for image_batch in dataset:\n",
    "            train_step(image_batch)\n",
    "\n",
    "        # 继续进行时为GIF生成图像\n",
    "        display.clear_output(wait=True)\n",
    "        generate_and_save_images(generator, epoch+1, seed)\n",
    "\n",
    "        # 每15个epoch保存一次模型\n",
    "        if(epoch + 1) % 15 == 0:\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "\n",
    "        print(\"time for epoch {} is {} sec\".format(epoch+1, time.time()-start))\n",
    "\n",
    "    # 最后一个epoch结束后生成图片\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator, epochs, seed)"
   ]
  },
  {
   "source": [
    "## 训练模型"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Creating variables on a non-first call to a function decorated with tf.function.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-e587ec6785a1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, epochs)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimage_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# 继续进行时为GIF生成图像\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/anaconda3/envs/no-gpu/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/anaconda3/envs/no-gpu/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m         raise ValueError(\"Creating variables on a non-first call to a function\"\n\u001b[0m\u001b[1;32m    621\u001b[0m                          \" decorated with tf.function.\")\n\u001b[1;32m    622\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Creating variables on a non-first call to a function decorated with tf.function."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}